{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# nltk.download()\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model import SimilarityAware,LSD,LSDA,cos_sim,loss_function,train,train2\n",
    "from input_functions import getVecDataFrame,extractData,getMaxSentLength\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "word_lem= nltk.stem.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hin=100\n",
    "Hout=100\n",
    "the_model = LSD(Hin,Hout)\n",
    "the_model.load_state_dict(torch.load(\"./NetModel.pth\"))\n",
    "\n",
    "the_model2 = LSDA(Hin,Hout,K_size=50,g_and_l=False)\n",
    "the_model2.load_state_dict(torch.load(\"./NetModel2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSD(\n",
       "  (head_Model): SimilarityAware(\n",
       "    (bi_gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "    (att): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (softMax): Softmax(dim=1)\n",
       "  )\n",
       "  (body_Model): SimilarityAware(\n",
       "    (bi_gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "    (att): Linear(in_features=200, out_features=1, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (softMax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSDA(\n",
       "  (LSD_model): LSD(\n",
       "    (head_Model): SimilarityAware(\n",
       "      (bi_gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "      (att): Linear(in_features=200, out_features=1, bias=True)\n",
       "      (tanh): Tanh()\n",
       "      (softMax): Softmax(dim=1)\n",
       "    )\n",
       "    (body_Model): SimilarityAware(\n",
       "      (bi_gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "      (att): Linear(in_features=200, out_features=1, bias=True)\n",
       "      (tanh): Tanh()\n",
       "      (softMax): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       "  (mlpLayer): Linear(in_features=200, out_features=50, bias=True)\n",
       "  (att1): myLinear(in_features=50, out_features=1, bias=False)\n",
       "  (att2): myLinear(in_features=50, out_features=50, bias=False)\n",
       "  (mlpLayer2): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softMax1): Softmax(dim=1)\n",
       "  (softMax2): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>postTimestamp</th>\n",
       "      <th>postText</th>\n",
       "      <th>postMedia</th>\n",
       "      <th>targetTitle</th>\n",
       "      <th>targetDescription</th>\n",
       "      <th>targetKeywords</th>\n",
       "      <th>targetParagraphs</th>\n",
       "      <th>targetCaptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>861</td>\n",
       "      <td>607668877594497024</td>\n",
       "      <td>Sun Jun 07 22:02:05 +0000 2015</td>\n",
       "      <td>[RT @WSJLive: This year's Tony nominees desrib...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tony Nominees' Craziest Moments on Stage</td>\n",
       "      <td>Tony Award nominees Carey Mulligan, Elisabeth ...</td>\n",
       "      <td></td>\n",
       "      <td>[Tony Award nominees Carey Mulligan, Elisabeth...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1702</td>\n",
       "      <td>607671137062010880</td>\n",
       "      <td>Sun Jun 07 22:11:03 +0000 2015</td>\n",
       "      <td>[Orphaned fruit bat pups nursed back to health...</td>\n",
       "      <td>[media/607671137062010881.jpg]</td>\n",
       "      <td>Going into bat to save a species: Dedication a...</td>\n",
       "      <td>North Sydney's Kukundi fruit bat shelter has e...</td>\n",
       "      <td>Adorable,images,orphaned,bat,pups,bundled,tiny...</td>\n",
       "      <td>[Wrapped in blankets and hand-fed, these winge...</td>\n",
       "      <td>[Four fruit bat pups who were injured after be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216</td>\n",
       "      <td>607672568057700352</td>\n",
       "      <td>Sun Jun 07 22:16:44 +0000 2015</td>\n",
       "      <td>[Ohio State’s Tyvis Powell learned that champi...</td>\n",
       "      <td>[media/607672568057700352.jpg]</td>\n",
       "      <td>Ohio State's Tyvis Powell Thinks He's Above Cu...</td>\n",
       "      <td>In the offseason following a championship se...</td>\n",
       "      <td>College Football, Breaking News</td>\n",
       "      <td>[In the offseason following a championship sea...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2192</td>\n",
       "      <td>607674674168926208</td>\n",
       "      <td>Sun Jun 07 22:25:07 +0000 2015</td>\n",
       "      <td>[China’s fishermen explain why they think the ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>China’s fishermen explain why they think the s...</td>\n",
       "      <td>Those who sail from Hainan island say the Sout...</td>\n",
       "      <td>china sea; china fish; south china; hainan sea...</td>\n",
       "      <td>[TANMEN, China — Little boats with noisy engin...</td>\n",
       "      <td>[Lu Yuyong, 51, looks up from a chart of the S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2285</td>\n",
       "      <td>607675444834398208</td>\n",
       "      <td>Sun Jun 07 22:28:10 +0000 2015</td>\n",
       "      <td>[RT @BBCSport: \"I'm living my dream\" - Watch w...</td>\n",
       "      <td>[media/607675444834398208.png]</td>\n",
       "      <td>BBC Sport - Lewis Hamilton 'living his dream' ...</td>\n",
       "      <td>Lewis Hamilton says Mercedes are enabling him ...</td>\n",
       "      <td></td>\n",
       "      <td>[Lewis Hamilton says Mercedes are enabling him...</td>\n",
       "      <td>[United\"s Matteo Darmian fights for the ball w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  id                   postTimestamp  \\\n",
       "0    861  607668877594497024  Sun Jun 07 22:02:05 +0000 2015   \n",
       "1   1702  607671137062010880  Sun Jun 07 22:11:03 +0000 2015   \n",
       "2    216  607672568057700352  Sun Jun 07 22:16:44 +0000 2015   \n",
       "3   2192  607674674168926208  Sun Jun 07 22:25:07 +0000 2015   \n",
       "4   2285  607675444834398208  Sun Jun 07 22:28:10 +0000 2015   \n",
       "\n",
       "                                            postText  \\\n",
       "0  [RT @WSJLive: This year's Tony nominees desrib...   \n",
       "1  [Orphaned fruit bat pups nursed back to health...   \n",
       "2  [Ohio State’s Tyvis Powell learned that champi...   \n",
       "3  [China’s fishermen explain why they think the ...   \n",
       "4  [RT @BBCSport: \"I'm living my dream\" - Watch w...   \n",
       "\n",
       "                        postMedia  \\\n",
       "0                              []   \n",
       "1  [media/607671137062010881.jpg]   \n",
       "2  [media/607672568057700352.jpg]   \n",
       "3                              []   \n",
       "4  [media/607675444834398208.png]   \n",
       "\n",
       "                                         targetTitle  \\\n",
       "0           Tony Nominees' Craziest Moments on Stage   \n",
       "1  Going into bat to save a species: Dedication a...   \n",
       "2  Ohio State's Tyvis Powell Thinks He's Above Cu...   \n",
       "3  China’s fishermen explain why they think the s...   \n",
       "4  BBC Sport - Lewis Hamilton 'living his dream' ...   \n",
       "\n",
       "                                   targetDescription  \\\n",
       "0  Tony Award nominees Carey Mulligan, Elisabeth ...   \n",
       "1  North Sydney's Kukundi fruit bat shelter has e...   \n",
       "2    In the offseason following a championship se...   \n",
       "3  Those who sail from Hainan island say the Sout...   \n",
       "4  Lewis Hamilton says Mercedes are enabling him ...   \n",
       "\n",
       "                                      targetKeywords  \\\n",
       "0                                                      \n",
       "1  Adorable,images,orphaned,bat,pups,bundled,tiny...   \n",
       "2                    College Football, Breaking News   \n",
       "3  china sea; china fish; south china; hainan sea...   \n",
       "4                                                      \n",
       "\n",
       "                                    targetParagraphs  \\\n",
       "0  [Tony Award nominees Carey Mulligan, Elisabeth...   \n",
       "1  [Wrapped in blankets and hand-fed, these winge...   \n",
       "2  [In the offseason following a championship sea...   \n",
       "3  [TANMEN, China — Little boats with noisy engin...   \n",
       "4  [Lewis Hamilton says Mercedes are enabling him...   \n",
       "\n",
       "                                      targetCaptions  \n",
       "0                                                 []  \n",
       "1  [Four fruit bat pups who were injured after be...  \n",
       "2                                                 []  \n",
       "3  [Lu Yuyong, 51, looks up from a chart of the S...  \n",
       "4  [United\"s Matteo Darmian fights for the ball w...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>truthJudgments</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthMode</th>\n",
       "      <th>truthClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>861</td>\n",
       "      <td>607668877594497024</td>\n",
       "      <td>[0.0, 0.6666667, 1.0, 1.0, 0.6666667]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1702</td>\n",
       "      <td>607671137062010880</td>\n",
       "      <td>[0.33333334000000003, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216</td>\n",
       "      <td>607672568057700352</td>\n",
       "      <td>[0.0, 0.0, 0.6666667, 0.33333334000000003, 0.0]</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2192</td>\n",
       "      <td>607674674168926208</td>\n",
       "      <td>[1.0, 0.6666667, 0.33333334000000003, 0.666666...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2285</td>\n",
       "      <td>607675444834398208</td>\n",
       "      <td>[0.33333334000000003, 0.6666667, 0.0, 0.0, 0.6...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  id  \\\n",
       "0    861  607668877594497024   \n",
       "1   1702  607671137062010880   \n",
       "2    216  607672568057700352   \n",
       "3   2192  607674674168926208   \n",
       "4   2285  607675444834398208   \n",
       "\n",
       "                                      truthJudgments  truthMean  truthMedian  \\\n",
       "0              [0.0, 0.6666667, 1.0, 1.0, 0.6666667]   0.666667     0.666667   \n",
       "1          [0.33333334000000003, 0.0, 0.0, 0.0, 0.0]   0.066667     0.000000   \n",
       "2    [0.0, 0.0, 0.6666667, 0.33333334000000003, 0.0]   0.200000     0.000000   \n",
       "3  [1.0, 0.6666667, 0.33333334000000003, 0.666666...   0.600000     0.666667   \n",
       "4  [0.33333334000000003, 0.6666667, 0.0, 0.0, 0.6...   0.333333     0.333333   \n",
       "\n",
       "   truthMode    truthClass  \n",
       "0   1.000000     clickbait  \n",
       "1   0.000000  no-clickbait  \n",
       "2   0.000000  no-clickbait  \n",
       "3   0.666667     clickbait  \n",
       "4   0.000000  no-clickbait  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = pd.read_json(\"../clickbait-17/clickbait17-train-170331/instances.jsonl\", lines=True)\n",
    "test_labels = pd.read_json(\"../clickbait-17/clickbait17-train-170331/truth.jsonl\", lines=True)\n",
    "\n",
    "test_data = test_data.sort_values(by=['id'])\n",
    "test_labels = test_labels.sort_values(by=['id'])\n",
    "\n",
    "test_data = test_data.reset_index()\n",
    "test_labels = test_labels.reset_index()\n",
    "\n",
    "display(test_data.iloc[0:5])\n",
    "display(test_labels.iloc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=np.array(['id','postText','targetDescription','targetParagraphs'])\n",
    "test_hd_bd=test_data[columns]\n",
    "df2_test = test_hd_bd.apply(lambda x: x.astype(str).str.lower())\n",
    "df2_test[\"id\"]=pd.to_numeric(df2_test[\"id\"])\n",
    "keys=df2_test.keys()\n",
    "\n",
    "for i in range(1,4):\n",
    "    df2_test[f\"{keys[i]}_proc\"]=df2_test[keys[i]].apply(word_lem.lemmatize)\n",
    "    df2_test[f\"{keys[i]}_proc\"]=df2_test[f\"{keys[i]}_proc\"].apply(regexp.tokenize)\n",
    "    df2_test[f\"{keys[i]}_proc\"]=df2_test[f\"{keys[i]}_proc\"].apply(lambda x: [word for word in x if word not in stopwords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(5, 7)\n"
     ]
    }
   ],
   "source": [
    "keys1=df2_test.keys()\n",
    "\n",
    "df2_w2vTest=df2_test[keys1[len(keys)]]\n",
    "# print(keys[len(keys)-1])\n",
    "print(range(len(keys)+1,len(keys1)))\n",
    "for i in range(len(keys)+1,len(keys1)):\n",
    "    df2_w2vTest=df2_w2vTest+df2_test[keys1[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [rt, wsjlive, year, tony, nominees, desribe, c...\n",
       "1       [orphaned, fruit, bat, pups, nursed, back, hea...\n",
       "2       [ohio, state, tyvis, powell, learned, champion...\n",
       "3       [china, fishermen, explain, think, sea, sail, ...\n",
       "4       [rt, bbcsport, living, dream, watch, lewis, ha...\n",
       "                              ...                        \n",
       "2454    [petition, calling, kay, burley, sacking, reac...\n",
       "2455    [rt, buzzfeednews, trooper, pulled, old, lady,...\n",
       "2456    [rt, irin, one, ever, top, sentence, anywhere,...\n",
       "2457    [video, espn, otl, study, reveals, college, at...\n",
       "2458    [charts, looking, numbers, companies, behind, ...\n",
       "Length: 2459, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2_w2vTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4183385, 4231170)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecLength=100\n",
    "modelW2v_test = Word2Vec(window=10, min_count=1, workers=4,vector_size=word2vecLength)\n",
    "modelW2v_test.build_vocab(df2_w2vTest, progress_per=1000)\n",
    "modelW2v_test.train(df2_w2vTest, total_examples=modelW2v_test.corpus_count, epochs=modelW2v_test.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading,body,labels_val=extractData(df2_test,test_labels)\n",
    "head_len=getMaxSentLength(heading)\n",
    "body_len=getMaxSentLength(body)\n",
    "norm_len=max(head_len,body_len)\n",
    "df_new,head_vec_test,body_vec_test=getVecDataFrame(heading,body,labels_val,norm_len,word2vecLength,modelW2v_test.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2459, 63, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_vec_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbar_shape: torch.Size([2459, 50, 50])\n",
      "Softmax_sum: tensor(1.0000, grad_fn=<SumBackward0>)\n",
      "A_prod: torch.Size([2459, 1, 50]) Transform_comb: torch.Size([2459, 1, 50])\n"
     ]
    }
   ],
   "source": [
    "P,Lh,Lb = the_model2.forward(head_vec_test,body_vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2459,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2459, 1]) torch.Size([2459, 200]) torch.Size([2459, 200])\n"
     ]
    }
   ],
   "source": [
    "#view shape of y_pred tuple\n",
    "print(P.shape,Lh.shape,Lb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax on the predictions P\n",
    "y_pred = torch.nn.functional.softmax(P, dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34e6e9a6e82c77d81154b5eff3eead86e95c27120a414427a075484bff8f67eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
